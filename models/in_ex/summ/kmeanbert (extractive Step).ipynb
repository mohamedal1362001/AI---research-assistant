{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EikLypqvuW4j"
      },
      "outputs": [],
      "source": [
        "!pip install torch\n",
        "!pip install pytorch-pretrained-bert\n",
        "!pip install sentence-transformers\n",
        "!pip install Rouge\n",
        "!pip install dataset\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0zN-699tcvC"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import torch\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6XMNW5o0CyjH"
      },
      "source": [
        "# Bert And Kmeans Code "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fK8mPR_XdSJW"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqgfh-dctlLZ",
        "outputId": "11cfc965-9c35-4e11-d68a-0266b61bcbe7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 2583414.07B/s]\n",
            "100%|██████████| 407873900/407873900 [00:24<00:00, 16416816.96B/s]\n"
          ]
        }
      ],
      "source": [
        "def bertSent_embeding(sentences):\n",
        "    # Add sentence head and tail as BERT requested\n",
        "    marked_sent = [\"[CLS] \" +item + \" [SEP]\" for item in sentences]\n",
        "    tokenized_sent = [tokenizer.tokenize(item ) for item in marked_sent]\n",
        "    # index to BERT vocabulary\n",
        "    indexed_tokens = [tokenizer.convert_tokens_to_ids(item) for item in tokenized_sent]\n",
        "    tokens_tensor = [torch.tensor([item]) for item in indexed_tokens]\n",
        "    # add segment id as BERT requested\n",
        "    segments_ids = [[1] * len(item) for ind,item in enumerate(tokenized_sent)]\n",
        "    segments_tensors = [torch.tensor([item]) for item in segments_ids]\n",
        "    # load BERT base model and set to evaluation mode\n",
        "    ##### bert_model = SentenceTransformer('stsb-bert-large')\n",
        "    #model.eval() is a kind of switch for some specific layers/parts of the model that behave differently during training and inference (evaluating) time. \n",
        "    #For example, Dropouts Layers, BatchNorm Layers etc.\n",
        "    #You need to turn them off during model evaluation, and .eval() will do it for you. In addition, \n",
        "    #the common practice for evaluating/validation is using torch.no_grad() in pair with model.eval() to turn off gradients computation:\n",
        "    bert_model.eval()\n",
        "    ## Output 12 layers of latent vector\n",
        "    assert len(tokens_tensor) == len(segments_tensors)\n",
        "    encoded_layers_list = []\n",
        "    for i in range(len(tokens_tensor)):\n",
        "        with torch.no_grad():\n",
        "            encoded_layers, _ = bert_model(tokens_tensor[i], segments_tensors[i])\n",
        "        encoded_layers_list.append(encoded_layers)\n",
        "    ## Use only the last layer vetcor **we can use others**\n",
        "    token_vecs_list =[layers[11][0] for layers in encoded_layers_list]\n",
        "    ## Pooling word vector to sentence vector, use mean pooling\n",
        "    sentence_embedding_list = [torch.mean(vec, dim=0).numpy() for vec in token_vecs_list]\n",
        "    return sentence_embedding_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "39ZIJ88Ztn_x",
        "outputId": "7f332d9a-cde6-4c1e-e62c-abcc2799a964"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' n_clusters =np.ceil(len(sentence_embedding_list)**0.5)\\nkmeans = KMeans(n_clusters=int(n_clusters))\\nkmeans = kmeans.fit(sentence_embedding_list)\\n#Compute minimum distances between one point and a set of points.\\n#get centers and compare with sentence_embedding by bert (\"centers is the most common sentences\")\\nsum_index,_ = pairwise_distances_argmin_min(kmeans.cluster_centers_, sentence_embedding_list,metric=\\'euclidean\\')\\nsum_index = sorted(sum_index)\\nreturn sum_index'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def kmeans_sumIndex(sentence_embedding_list):\n",
        "  try:\n",
        "    n_clusters =5\n",
        "    #np.ceil(len(sentence_embedding_list)**0.5)\n",
        "    kmeans = KMeans(n_clusters=int(n_clusters))\n",
        "    kmeans = kmeans.fit(sentence_embedding_list)\n",
        "    #Compute minimum distances between one point and a set of points.\n",
        "    #get centers and compare with sentence_embedding by bert !!!!(\"centers is the most common sentences\")\n",
        "    sum_index,_ = pairwise_distances_argmin_min(kmeans.cluster_centers_, sentence_embedding_list,metric='euclidean')\n",
        "    sum_index = sorted(sum_index)\n",
        "    return sum_index\n",
        "  except:\n",
        "    n_clusters =1\n",
        "    #np.ceil(len(sentence_embedding_list)**0.5)\n",
        "    kmeans = KMeans(n_clusters=int(n_clusters))\n",
        "    kmeans = kmeans.fit(sentence_embedding_list)\n",
        "    #Compute minimum distances between one point and a set of points.\n",
        "    #get centers and compare with sentence_embedding by bert !!!!(\"centers is the most common sentences\")\n",
        "    sum_index,_ = pairwise_distances_argmin_min(kmeans.cluster_centers_, sentence_embedding_list,metric='euclidean')\n",
        "    sum_index = sorted(sum_index)\n",
        "    return sum_index\n",
        "''' n_clusters =np.ceil(len(sentence_embedding_list)**0.5)\n",
        "kmeans = KMeans(n_clusters=int(n_clusters))\n",
        "kmeans = kmeans.fit(sentence_embedding_list)\n",
        "#Compute minimum distances between one point and a set of points.\n",
        "#get centers and compare with sentence_embedding by bert (\"centers is the most common sentences\")\n",
        "sum_index,_ = pairwise_distances_argmin_min(kmeans.cluster_centers_, sentence_embedding_list,metric='euclidean')\n",
        "sum_index = sorted(sum_index)\n",
        "return sum_index'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXVeMfL2tXx8"
      },
      "outputs": [],
      "source": [
        "def bertSummarize(text):\n",
        "  sentences = sent_tokenize(text)\n",
        "  sentence_embedding_list = bertSent_embeding(sentences)\n",
        "  sum_index = kmeans_sumIndex(sentence_embedding_list)\n",
        "  summary = ''.join([sentences[ind] for ind in sum_index])\n",
        "  return summary"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3Lpw__oC9QK"
      },
      "source": [
        "# DataLoad And PreProcess\n",
        "**this data has changed to  cnn-dailymail**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxccpvcAuRv1"
      },
      "outputs": [],
      "source": [
        "Data_Frame_Train_inputs =pd.read_csv(\"https://github.com/bwallace/RCT-summarization-data/raw/main/train-inputs.csv\") #Cochrane train\n",
        "Data_Frame_Train_targets =pd.read_csv(\"https://github.com/bwallace/RCT-summarization-data/raw/main/train-targets.csv\") #Cochrane train\n",
        "#------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "#Data_Frame_val_inputs =pd.read_json(\"https://drive.google.com/u/0/uc?id=1-FmSaBFQPB3Det_t6VHeBJjsJKVEBYRq&export=download\") #Cochrane validation\n",
        "\n",
        "#Data_Frame_val_inputs =pd.read_csv(\"https://github.com/bwallace/RCT-summarization-data/raw/main/dev-inputs.csv\") #Cochrane validation\n",
        "#Data_Frame_val_targets =pd.read_csv(\"https://github.com/bwallace/RCT-summarization-data/raw/main/dev-targets.csv\") #Cochrane validation\n",
        "#------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "#Data_Frame_Test_inputs =pd.read_csv(\"https://github.com/bwallace/RCT-summarization-data/raw/main/dev-inputs.csv\") #Cochrane test\n",
        "#Data_Frame_Test_targets =pd.read_csv(\"https://github.com/bwallace/RCT-summarization-data/raw/main/dev-targets.csv\") #Cochrane test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "k25uDGr1dwkJ",
        "outputId": "1e1acb91-c0b2-482e-f30f-41c635d68e40"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"test_Inputs = Data_Frame_val_inputs[['ReviewID','Title','Abstract']]\\ntest_Targets = Data_Frame_val_targets[['ReviewID','Target']]\\n\\ntest_Inputs = test_Inputs.dropna()\\nval_Targets = val_Targets.dropna()\\n\""
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Train_Inputs = Data_Frame_Train_inputs[['ReviewID','Title','Abstract']]\n",
        "Train_Targets = Data_Frame_Train_targets[['ReviewID','Target']]\n",
        "\n",
        "for i in Train_Inputs.index:\n",
        "  val =  Train_Inputs.at[i,\"Abstract\"]\n",
        "  if val != val:\n",
        "    val = Train_Inputs.at[i,\"Title\"]\n",
        "  Train_Inputs.at[i,\"Abstract\"] = val\n",
        "\n",
        "#Train_Inputs = Train_Inputs.dropna()\n",
        "#Train_Targets =Train_Targets.dropna()\n",
        "#------------------------------------------------------------------------------\n",
        "'''val_Inputs = Data_Frame_val_inputs[['ReviewID','Title','Abstract']]\n",
        "val_Targets = Data_Frame_val_targets[['ReviewID','Target']]\n",
        "\n",
        "val_Inputs['REVIEWS'] = val_Inputs['Title'] + ' ' +val_Inputs['Abstract']#combine abstract and title\n",
        "\n",
        "val_Inputs = val_Inputs.dropna()\n",
        "val_Targets =val_Targets.dropna()'''\n",
        "#------------------------------------------------------------------------------\n",
        "'''test_Inputs = Data_Frame_val_inputs[['ReviewID','Title','Abstract']]\n",
        "test_Targets = Data_Frame_val_targets[['ReviewID','Target']]\n",
        "\n",
        "test_Inputs = test_Inputs.dropna()\n",
        "val_Targets = val_Targets.dropna()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2509
        },
        "id": "dZ_dgRp_RuLV",
        "outputId": "87d5a453-1263-4842-a682-0eff972b1104"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a4d7efba-ccc1-4390-9361-d37d14c17b0f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ReviewID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CD007697</td>\n",
              "      <td>Aggressive surgical effort and improved surviv...</td>\n",
              "      <td>Residual disease after initial surgery for ova...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CD000174</td>\n",
              "      <td>Prophylactic indomethacin therapy in the first...</td>\n",
              "      <td>To determine whether a course of low-dose indo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CD000174</td>\n",
              "      <td>Indomethacin reduces the risks of severe intra...</td>\n",
              "      <td>A prospective, random selection, double-blind ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CD000174</td>\n",
              "      <td>Administration of indomethacin for the prevent...</td>\n",
              "      <td>One hundred twenty-two preterm infants were en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CD000174</td>\n",
              "      <td>Early intravenous indomethacin prolongs respir...</td>\n",
              "      <td>Infants weighing 1500 g at birth requiring eit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CD000174</td>\n",
              "      <td>Low-dose indomethacin therapy and extension of...</td>\n",
              "      <td>We enrolled 61 neonates of 600 to 1250 gm birt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CD000174</td>\n",
              "      <td>Long-term effects of indomethacin prophylaxis ...</td>\n",
              "      <td>The prophylactic administration of indomethaci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>CD000174</td>\n",
              "      <td>Randomized low-dose indomethacin trial for pre...</td>\n",
              "      <td>We admitted 36 preterm neonates (600 to 1250 g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CD000174</td>\n",
              "      <td>Prophylactic indomethacin for prevention of in...</td>\n",
              "      <td>The impact of early prophylactic use of intrav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>CD000174</td>\n",
              "      <td>Effects of early indomethacin administration o...</td>\n",
              "      <td>A previous study found that early intravenous ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CD000174</td>\n",
              "      <td>Prevention of symptomatic patent ductus arteri...</td>\n",
              "      <td>To determine the efficacy of indomethacin to p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CD000174</td>\n",
              "      <td>Randomized indomethacin trial for prevention o...</td>\n",
              "      <td>We admitted 48 preterm neonates (600 to 1250 g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>CD000174</td>\n",
              "      <td>[Indomethacin in the prevention of subependyma...</td>\n",
              "      <td>The results of a double blind study to evaluat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>CD000174</td>\n",
              "      <td>Indomethacin therapy on the first day of life ...</td>\n",
              "      <td>To investigate the optimal timing for treatmen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>CD000174</td>\n",
              "      <td>Indomethacin prophylaxis for patent ductus art...</td>\n",
              "      <td>Very low birth weight (VLBW, less than 1500 g)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>CD008805</td>\n",
              "      <td>White phosphorus burns and massive hemolysis.</td>\n",
              "      <td>White phosphorus burns and massive hemolysis.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>CD008805</td>\n",
              "      <td>The treatment of chemical burns: specialized d...</td>\n",
              "      <td>The treatment of chemical burns: specialized d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>CD000248</td>\n",
              "      <td>Trial of long-term anticoagulant therapy in th...</td>\n",
              "      <td>The clinical features of 49 patients who had s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4d7efba-ccc1-4390-9361-d37d14c17b0f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4d7efba-ccc1-4390-9361-d37d14c17b0f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4d7efba-ccc1-4390-9361-d37d14c17b0f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    ReviewID                                              Title  \\\n",
              "0   CD007697  Aggressive surgical effort and improved surviv...   \n",
              "1   CD000174  Prophylactic indomethacin therapy in the first...   \n",
              "2   CD000174  Indomethacin reduces the risks of severe intra...   \n",
              "3   CD000174  Administration of indomethacin for the prevent...   \n",
              "4   CD000174  Early intravenous indomethacin prolongs respir...   \n",
              "5   CD000174  Low-dose indomethacin therapy and extension of...   \n",
              "6   CD000174  Long-term effects of indomethacin prophylaxis ...   \n",
              "7   CD000174  Randomized low-dose indomethacin trial for pre...   \n",
              "8   CD000174  Prophylactic indomethacin for prevention of in...   \n",
              "9   CD000174  Effects of early indomethacin administration o...   \n",
              "10  CD000174  Prevention of symptomatic patent ductus arteri...   \n",
              "11  CD000174  Randomized indomethacin trial for prevention o...   \n",
              "12  CD000174  [Indomethacin in the prevention of subependyma...   \n",
              "13  CD000174  Indomethacin therapy on the first day of life ...   \n",
              "14  CD000174  Indomethacin prophylaxis for patent ductus art...   \n",
              "15  CD008805      White phosphorus burns and massive hemolysis.   \n",
              "16  CD008805  The treatment of chemical burns: specialized d...   \n",
              "17  CD000248  Trial of long-term anticoagulant therapy in th...   \n",
              "\n",
              "                                             Abstract  \n",
              "0   Residual disease after initial surgery for ova...  \n",
              "1   To determine whether a course of low-dose indo...  \n",
              "2   A prospective, random selection, double-blind ...  \n",
              "3   One hundred twenty-two preterm infants were en...  \n",
              "4   Infants weighing 1500 g at birth requiring eit...  \n",
              "5   We enrolled 61 neonates of 600 to 1250 gm birt...  \n",
              "6   The prophylactic administration of indomethaci...  \n",
              "7   We admitted 36 preterm neonates (600 to 1250 g...  \n",
              "8   The impact of early prophylactic use of intrav...  \n",
              "9   A previous study found that early intravenous ...  \n",
              "10  To determine the efficacy of indomethacin to p...  \n",
              "11  We admitted 48 preterm neonates (600 to 1250 g...  \n",
              "12  The results of a double blind study to evaluat...  \n",
              "13  To investigate the optimal timing for treatmen...  \n",
              "14  Very low birth weight (VLBW, less than 1500 g)...  \n",
              "15      White phosphorus burns and massive hemolysis.  \n",
              "16  The treatment of chemical burns: specialized d...  \n",
              "17  The clinical features of 49 patients who had s...  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Train_Inputs.head(18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IFqCaikry6R"
      },
      "outputs": [],
      "source": [
        "validation_inputs_cleared = val_Inputs.drop_duplicates(subset=['ReviewID'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0JCZd-Dz6AQ",
        "outputId": "eedc117a-c8d7-4dad-9192-d15f5164beb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40497\n"
          ]
        }
      ],
      "source": [
        "print(len(Train_Inputs ))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "K0N9oGwzCmJt"
      },
      "source": [
        "# **Combine matched reviews in id** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owqXxSlPf9Bs",
        "outputId": "43c30f21-fd89-4fb6-bf5a-df32967ef8e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-15-dcfee36aad03>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  validation_inputs_cleared['REVIEWS'][key] = validation_inputs_cleared['REVIEWS'][key] + val_Inputs['REVIEWS'][KEY]\n"
          ]
        }
      ],
      "source": [
        "for key,ID in validation_inputs_cleared['ReviewID'].items():\n",
        "  for KEY,id in val_Inputs['ReviewID'].items():\n",
        "    if ID == id :\n",
        "      if val_Inputs['REVIEWS'][KEY] not in validation_inputs_cleared['REVIEWS'][key]:\n",
        "        validation_inputs_cleared['REVIEWS'][key] = validation_inputs_cleared['REVIEWS'][key] + val_Inputs['REVIEWS'][KEY]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufreTsbizrNy"
      },
      "outputs": [],
      "source": [
        "validation_inputs_cleared.head(3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6eOm8B_PDf-d"
      },
      "source": [
        "# **Extraction step**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-P-8Yed7OJ8J",
        "outputId": "cb923a50-fa3d-4507-9f82-a6e992891dc7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RangeIndex(start=0, stop=40497, step=1)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Train_Inputs.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OWuedmsLTNH7",
        "outputId": "2fb79db7-6855-4442-c00e-e0fc9566e98e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "key 0 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-16-1f71e1592461>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Extracted_sent['Abstract'][key] = bertSummarize(Train_Inputs['Abstract'][key])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "key 1 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-16-1f71e1592461>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Extracted_sent['Abstract'][key] = bertSummarize(Train_Inputs['Abstract'][key])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "key 2 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-16-1f71e1592461>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Extracted_sent['Abstract'][key] = bertSummarize(Train_Inputs['Abstract'][key])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "key 3 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-16-1f71e1592461>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Extracted_sent['Abstract'][key] = bertSummarize(Train_Inputs['Abstract'][key])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "key 4 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-16-1f71e1592461>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Extracted_sent['Abstract'][key] = bertSummarize(Train_Inputs['Abstract'][key])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "key 5 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-16-1f71e1592461>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Extracted_sent['Abstract'][key] = bertSummarize(Train_Inputs['Abstract'][key])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "key 6 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-16-1f71e1592461>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Extracted_sent['Abstract'][key] = bertSummarize(Train_Inputs['Abstract'][key])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "key 7 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-16-1f71e1592461>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Extracted_sent['Abstract'][key] = bertSummarize(Train_Inputs['Abstract'][key])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "key 8 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-16-1f71e1592461>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Extracted_sent['Abstract'][key] = bertSummarize(Train_Inputs['Abstract'][key])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "key 9 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-16-1f71e1592461>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Extracted_sent['Abstract'][key] = bertSummarize(Train_Inputs['Abstract'][key])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "key 10 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-16-1f71e1592461>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Extracted_sent['Abstract'][key] = bertSummarize(Train_Inputs['Abstract'][key])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "key 11 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-16-1f71e1592461>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Extracted_sent['Abstract'][key] = bertSummarize(Train_Inputs['Abstract'][key])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "key 12 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-16-1f71e1592461>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Extracted_sent['Abstract'][key] = bertSummarize(Train_Inputs['Abstract'][key])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "key 13 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "<ipython-input-16-1f71e1592461>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Extracted_sent['Abstract'][key] = bertSummarize(Train_Inputs['Abstract'][key])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "key 14 \n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1f71e1592461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTrain_Inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ReviewID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"key\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mExtracted_sent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Abstract'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbertSummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrain_Inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Abstract'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-bb96d0520e8e>\u001b[0m in \u001b[0;36mbertSummarize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0msentence_embedding_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbertSent_embeding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0msum_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans_sumIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_embedding_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msum_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-bcaf8111f6ef>\u001b[0m in \u001b[0;36mbertSent_embeding\u001b[0;34m(sentences)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mencoded_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegments_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mencoded_layers_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m         encoded_layers = self.encoder(embedding_output,\n\u001b[0m\u001b[1;32m    732\u001b[0m                                       \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                                       output_all_encoded_layers=output_all_encoded_layers)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mall_encoder_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mall_encoder_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, attention_mask)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mself_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mmixed_query_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mmixed_key_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0mmixed_value_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for i in Train_Inputs.index:\n",
        "  Train_Inputs.at[i,'Abstract']  = bertSummarize(Train_Inputs.at[i,'Abstract'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "S13lFCiZDuue"
      },
      "source": [
        "**Save Dataframe into csv file to be ready to the next step**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIc8Ak8YaHd8"
      },
      "outputs": [],
      "source": [
        "Extracted_sent.to_csv(r'/content/FinalA1_100.csv')\n",
        "Extracted_sent.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JX2F9aUKBIhW"
      },
      "outputs": [],
      "source": [
        "for i in Data_Frame_val_inputs['Text']:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iWEqafCfkdb",
        "outputId": "dd768e98-363e-4b90-a977-c19e737e5b1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      In a combinatorial auction m heterogenous indi...\n",
              "1      We consider the free-rider problem in peer-to-...\n",
              "2      Determining how to transport delay-sensitive v...\n",
              "3      Botnets pose a serious threat to the health of...\n",
              "4      Under many protocols-in computerized settings ...\n",
              "                             ...                        \n",
              "495    Mobile Online Social Networks (mOSNs) have rec...\n",
              "496    A recent trend in optimizing Internet browsing...\n",
              "497    System administrators have utilized log analys...\n",
              "498    Continuous fine-grain status monitoring of a c...\n",
              "499    Highly interactive web applications that offer...\n",
              "Name: Text, Length: 500, dtype: object"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_Frame_val_inputs['Text'][0:500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SE1TsWsj_SR"
      },
      "outputs": [],
      "source": [
        "print(''.join(str(v) for v in Data_Frame_val_inputs['Text']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MY6zVOKAkj86",
        "outputId": "c60866e6-53be-4e01-96bc-4ab5cce2851c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'In a combinatorial auction m heterogenous indivisible items are sold to n bidders.\\nThis paper considers settings in which the valuation functions of the bidders are known to be complement-free (a.k.a. subadditive).\\nWe provide several approximation algorithms for the social-welfare maximization problem in such settings.\\nFirstly, we present a logarithmic upper bound for the case that the access to the valuation functions is via demand queries.\\nFor the weaker value queries model we provide a tight O(√ m) approximation.\\nUnlike the other algorithms we present, this algorithm is also incentive compatible.\\nFinally, we present two approximation algorithms for the more restricted class of XOS valuations: A simple deterministic algorithm that provides an approximation ratio of 2 and an optimal e e−1 approximation achieved via randomized rounding.\\nWe also present optimal lower bounds for both the demand oracles model and the value oracles model.\\nCF valuations to within a factor of 2 − , for any constant > 0.\\nbetter than e/(e − 1).\\nThe last theorem shows that our algorithm for the class XOS is tight.1.3 Handling Selfishness.\\nIn many settings in which the combinatorial auction problem arises, it is natural to assume that the bidders are selfish.\\nThat is, the bidders are interested only in maximizing their own utility, and might therefore misreport their preferences if it suits their interests.\\nWe are therefore interested in truthful algorithms that by introducing payments guarantee that if each bidder is to simply report his true value he will maximize his profit.\\nSurprisingly, to date, very few computationally-feasible truthful mechanisms for this problem are known that do not apply only to very restricted single-parameter domains.\\nWe present an approximation algorithm that makes use of value queries only, and ensures truthfulness.\\nThis approximation ratio may seem quite bad when contrasted with the fact that for the class of submodular valuations constant-approximation algorithms that use only value queries exist (e.g., by Lehmann et al. [12]).\\nHowever, it turns out that this algorithm is optimal in the value oracle model, even if all bidders have XOS valuations, and even ignoring truthfulness constraints: Theorem 1.6 Every approximation algorithm for combinatorial auctions with XOS bidders that uses only value queries, requires an exponential number of queries to achieve an approximation ratio better than m 1 2 − , for any constant > 0.1.4 Subsequent Work.\\nSubsequently to this paper, Feige [9] improved the upper bound for combinatorial auctions with complement-free valuations to 2.\\nThis upper bound uses demand queries.\\nThe communication lower bound we present implies that this upper bound is tight.We now discuss subsequent work related to submodular valuations.\\nKhot, Lipton, Markakis, and Mehta [11] showed that no approximation better than e e−1 using value queries only is possible, unless P = N P .\\nThis lower bound was recently strengthened to an unconditional one by Mirrokni et al. [?]\\n.\\nVondrak [21] has shown that this lower bound is tight by exhibiting a matching upper bound that uses value queries only.\\nIn the demand queries model Feige and Vondrak [10] obtained an approximation ratio slightly better than e e−1 .\\nThey also show that approximating the welfare with demand oracle in this case is APX-hard.\\nAnother line of research which stemmed in this paper is obtaining truthful mechanisms for combinatorial auctions with complement-free valuations.\\nDobzinski [4] obtained an approximation ratio of O(log m log log m) for subadditive valuations using a randomized mechanism, improving over a previous result of [6].\\nOne of the main ingredients in these results is the 2-approximation algorithm for XOS valuations presented in this paper.\\nIn addition, Feige [9], showed how to convert the log m log log m -approximation algorithm of this paper to a truthful one (under a weaker notion of truthfulness).\\nThe best deterministic mechanism for complement-free valuations is still the O( √ m)-mechanism presented in this paper.Dobzinski and Nisan [5] proved that one cannot achieve a much better approximation factor using this type of algorithms -maximal in range algorithms (see the discussion in Section 5).1.5 Open Questions.\\nThis paper and subsequent work determined the optimal bounds possible for the upper levels of the hierarchy, namely combinatorial auctions with XOS and complement-free valuations.\\n• The main open question is closing the gap between the known upper and lower bounds for submodular valuations in the demand oracles model.\\nIn particular, no communication lower bound is known.\\n• It would also be interesting to achieve these approximation ratios using combinatorial algorithms (most state-of-the-art algorithms are based on randomized rounding of the LP relaxation of the problem).\\n• Another major open question which is still open is to determine how well truthful mechanisms can approximate the welfare in all levels of the hierarchy.2.\\nDefinition and Representation of XOS.\\nThis section discusses the definition and representation of XOS valuations.\\nRecall, that as discussed in the introduction the class of XOS valuations strictly contains the class of submodular valuations [12].\\nA valuation is called additive (a.k.a. linear) if for all S ⊆ M , v(S) = Σ j∈S v({j}).\\nThus, an additive valuation is defined by the values a 1 , ..., a m it assigns to items 1, ..., m respectively.\\nWe describe an additive valuations by the following clause:(x 1 : a 1 ∨ x 2 : a 2 ∨ ... ∨ x m : a m )We can now define XOS valuations: Definition 2.1 A valuation v is said to be XOS if there is a set of additive valuations {w 1 , ..., w t }, such that v(S) = max k {w k (S)} for all S ⊆ M .\\nWe denote XOS valuations by(x 1 : w 1 ({x 1 }) ∨ ... ∨ x m : w 1 ({x m })) ⊕ ... ⊕ (x 1 : w t ({x 1 }) ∨ ... ∨ x m : w t ({x m }))where each of the clauses connected by the ⊕ sign represents an additive valuation.We note that the number of clauses t might be exponentially large.\\nWe call a clause of an additive valuation w, for which v(S) = max k {w k (S)}, a maximizing clause for S in v (if there are several such clauses we arbitrarily choose one).\\nAn XOS oracle is an oracle that given a bundle S returns a maximizing clause for S (for a specific valuation v).2.1 Efficiently Simulating XOS and Demand Queries.\\nWe now show that if the input is given in the form of an XOS expression, XOS oracles and demand oracles can be simulated in time that is polynomial in the input size.\\nWe also prove that if all valuations are submodular then value queries can simulate XOS queries in polynomial time.\\nTherefore, if all valuations are submodular, the algorithm presented in this section requires demand queries only (recall that a value query can be simulated by a polynomial number of demand queries [2]).\\nProposition 2.1 Given an XOS valuation as an XOS expression, we can evaluate both XOS queries and demand queries in time polynomial in the input size.Proof.\\nGiven an XOS valuation and a vector of prices we wish to simulate a demand oracle.\\nFirst, let us note that it is easy to simulate a demand oracle for an additive valuation in polynomial time, by simply choosing all profitable items.\\nSince the input is given as an XOS formula and each clause is an additive valuation, it is enough to simulate a demand oracle for each clause and choose the most profitable option.\\nThe entire process requires time polynomial in the input size.If the input is not given as an XOS expression, then we do not know how to answer XOS queries given only a demand oracle.\\nHowever, for the more restricted class of submodular valuations, even the weaker value oracle suffices to answer XOS queries, as the following proposition shows: Proposition 2.2 An XOS clause for a bundle S of a submodular valuation v can be calculated in polynomial time using value queries only.Proof.\\nGiven a bundle S we show how to construct the corresponding XOS clause.\\nFix some arbitrary order of the items in S. Without loss of generality, let S = {1, . . . , |S|}.\\nLet t j be the marginal utility of the j\\'th item given the previous j − 1 items:t j = v({1, . . . , j}) − v({1, . . . , j − 1}).\\nThe XOS clause is (t 1 ∨ . . . ∨ t |S| ).\\nAll that we have to prove is that v(S) = Σ j∈S t j , and that for every T ⊆ S, v(T ) ≥ Σ j∈T t i .\\nFor that we use an alternative definition of submodular valuations (see [12] for an equivalence proof): a valuation v is submodular if for every item j, and bundlesW, T , W ⊆ T , j / ∈ T , we have that v(W ∪ {j}) − v(W ) ≥ v(T ∪ {j}) − v(T ).\\nThe first property holds simply by construction.\\nTo see that v(T ) ≥ Σ j∈T t i , fix T , and let t T j be the marginal utility of item j in T , using the same order we used in S (that is, order the items in S, and delete items that are not in T , while keeping the relative order of the rest of the items).\\nRecall that an alternative definition of submodular valuation says that the marginal utility does not decrease when items are deleted, hence v(T ) = Σ j∈T t T i ≥ Σ j∈T t i Finally, to show that this clause can be constructed using value queries only, observe that we only have to calculate the marginal utility of an item, which can be done by two value queries for each item.3.\\nApproximating the Welfare with Demand Oracles.\\nRandomized rounding of an LPrelaxation of a problem is a standard technique, and our algorithms use it.\\nHowever, when one attempts randomized rounding on packing problems such as combinatorial auctions the results are not good; A randomized choice will very likely yield non-feasible solutions, unless the probabilities chosen reduce the expected quality of solution by a large O( √ m) factor.Both algorithms we present in this section start with a randomized rounding procedure for obtaining a \"pre-allocation\".\\nThis allocation has a value that is close to the optimum, but unfortunately is not feasible.\\nFeasibility issues are handled differently in the complement free and the XOS cases, and indeed a much better ratio is obtained for the XOS case.Before describing the randomized rounding procedure, let us recall the standard LP relaxation for combinatorial auctions:Maximize: Σ i,S x i,S v i (S) Subject to: -For each item j: Σ i,S|j∈S x i,S ≤ 1 -for each bidder i: Σ S x i,S ≤ 1 -for each i, S: x i,S ≥ 0Even though the linear program has exponentially many variables, it may still be solved in polynomial time.\\nThis is done by solving the dual linear program using the ellipsoid method.\\nUsing the ellipsoid method requires a \"separation\" oracle, and this may be directly implemented using the demand oracles of the bidders.\\nThis was first proven by Nisan and Segal [19], and in more details by Blumrosen and Nisan [2].\\nThe pre-allocation is obtained via randomized rounding as follows: For each bidder i we independently choose a set S i by performing the following random experiment: each set S is chosen with probability x i,S , and the empty set is chosen with probability 1 − Σ S x i,S .\\nObserve that the randomized rounding solution outputs an integral solution with an expected value of OP T * , the optimal fractional solution.\\nHowever, the solution is not feasible, as an item might be allocated to more than one bidder.\\nThe two algorithms we present greatly differ in how they solve this infeasibility.A word about the oracles needed to implement our algorithms.\\nThe algorithm for complement-free valuations we present in this section requires access to a demand oracle (for each specific valuation v).\\nBoth algorithms for XOS valuations we present require in addition access to an XOS oracle.3.1 Complement-Free Valuations.\\nIndeed, the pre-allocation produces a non-feasible solution.\\nHowever, these non-feasible solutions are only a logarithmic factor away from feasibility (in the sense that with high probability each item is allocated at most a logarithmic number of times).\\nFor general valuations this fact does not help, but as we will show it suffices for CF valuations (see also [7] for another setting, the k-duplicates version of combinatorial auctions, in which this fact leads to good approximations).\\nThe main observation at the heart of our algorithm is that one may partition this logarithmicallynon-feasible solution into a logarithmic-size family of feasible solutions.\\nFor the case of complement-free valuations, the quality of one of these solutions can be bounded from below.The original version of the algorithm claimed a ratio of O(log m).\\nFeige [9] observed that the algorithm actually provides an approximation ratio of O( log m log log m ), and this is the ratio that is presented here.\\nWe also note that Feige [9] presents an example which shows that the approximation ratio of the algorithm is at least Ω( log m log log m ).\\n(i) Use randomized rounding to find a \"pre-allocation\" S 1 , ..., S n of pairs < i, S i > with the following properties, where k = O( log m log log m ):• Each item j appears at most k times in {S i } i , with j ∈ S i .\\n• i v i (S i ) ≥ 1 3 · (Σ i,S x i,S v i (S)).\\n(ii) For each bidder i, partition S i into a disjoint union S i = S 1 i ∪ ... ∪ S k isuch that for each 1 ≤ i 1 < i 2 ≤ n and 1 ≤ r ≤ k, it holds that S r i1 ∩ S r i2 = ∅.\\nThis is done as follows: for each i = 1, ..., n and each r = 1, ..., k, we let S r i = {j ∈ S i |j appears in exactly r − 1 of the sets S 1 , ..., S i−1 }.\\n(iii) Find the r that maximizes i v i (S r i ), and for each i allocate T i = S r i to bidder i. (iv) If there is a bidder i with v i (M ) ≥ Σ i v i (T i ) then allocate i all items (and allocate nothing to the rest of the bidders).\\nTheorem 3.1 If all input valuations are complement-free then the algorithm produces an allocation that is an O(k) = O( log m log log m )-approximation to the optimal one.We now prove the theorem.\\nTowards this end, let us keep track of the \"quality\" of solution implied by the intermediate steps.\\n(i) The randomized rounding procedure returns the optimal fractional solution OP T * = Σ i,S x i,S v i (S), which is an upper bound to the value of the integral optimal allocation, OP T .\\nThe detailed calculations needed to prove that this step indeed ends with a solution that satisfies all the required conditions are given later.\\nAt this point we will indicate the types of calculations used and what they yield.\\nFrom the first inequality of the LP and using standard probability bounds one can show that for every item j, the probability that it appears in more than k chosen sets is exponentially small in k.\\nThe expected value of i v i (S i ) at this stage is only slightly less than Σ i,S x i,S v i (S) = OP T * .\\nIt follows that with very high probability none of the required constraints are violated, and thus we havei v i (S) ≥ 1 3 · OP T * Dobzinskiet al.: Approximations Algorithms for CA\\'s with CF Bidders Mathematics of Operations Research 00(0), pp.\\nxxx-xxx, c 20xx INFORMS 7 (ii) The main point here is that indeed for every fixed r, the sets {S r i } i are pairwise disjoint and are thus a valid allocation.\\nThis follows directly fromthe construction, as every duplicate instances of every item j are allocated to sets S r i with sequentially increasing r. Note that we always keep r ≤ k since each item appears in at most k sets in {S i }.\\n(iii) The crucial use of complement-freeness comes here: since for each fixed i, S i = r S r i , the fact that v i is complement free implies that r v i (S r i ) ≥ v i (S i ).\\nBy summing over all i we get that .\\nThus, the allocation T 1 = S r 1 , ..., T n = S r n is an O( log(m) log log m ) approximation to the optimal allocation (and even to the optimal fractional allocation).\\nr i v i (S r i ) = i r v i (S r i ) ≥ i v i (S i ) ≥ 1 3 ·OP T * .\\nIt3.1.1 Details of Stage (i).\\nFor each j ∈ M , let E j denote the random variable that indicates whether j was allocated more than k times.\\nLet B be the random variable that indicates whetherv i (S i ) < 1 3 OP T * .\\nWe will prove that Pr[∨ j E j ∨ B] < 5 6 .\\nWe first prove that Pr[∨ j E j ] < 1n .\\nFix an item j. Let Z i,j be the random variable that determines whether j ∈ S i .\\nObviously, Z i,j receives values in {0, 1}.\\nBecause of the randomized rounding method we used, we have that the variables {Z i,j } i are independent.\\nWe define Z j = Σ i Z i,j (i.e., Z j is the number of times item j appears in {S i }).\\nBy the linearity of expectation and the first condition of the LP formulation we have that E[Z j ] ≤ 1.\\nWe now use the following known proposition, (see, e.g., the book by Mitzenmacher and Upfal [14]):Lemma 3.1 Let X 1 ,...,X n (for sufficiently large n) be independent Bernoulli trials such that for 1 ≤ i ≤ m, Pr[X i = 1] = p i , and Σ i p i = 1.\\nLet X = X 1 + ... + X m .\\nThen Pr[X > 3 log m log log m ] ≤ 1 m 2and thus we have that Pr[item j appears in more than log m 3 log log m bundles in{S i }] ≤ 1 m 2By applying the union bound we get that the probability that any one of the items appears in more than log m 3 log log m bundles in {S i } is smaller than m · 1 m 2 = 1 m .\\nWe will now prove that Pr[B] < 3 4 .\\nW.l.o.g. max i v i (M ) = 1 (otherwise, we can divide all valuations by max i v i (M )).\\nIf OP T * ≤ 3, then giving M to the bidder that maximizes v i (M ), is a feasible allocation which provides a good approximation.\\nTherefore, from now on we assume that OP T * > 3.\\nLet A be the random variable that gets the value of Σ i v i (S i ) after step (i).\\nWe will see that A ≥ Σ i v i (S) 3 with high probability.We make use of the following corollary from Chebyshev\\'s inequality:Lemma 3.2 Let X be the sum of independent random variables, each of which lies in [0,1], and letµ = E[X].\\nThen, for any α > 0, Pr[|X − µ| ≥ α] ≤ µ α 2 .\\nWe can now upper bound the probability that event B occurs.Pr[B] = Pr[A < OP T * 3 ] ≤ Pr[|A − OP T * | ≥ 2OP T * 3 ] ≤ 9 4OP T * ≤ 3 4the last inequality is because OP T * > 3.\\nTherefore, using the union bound:Pr[∨ m t=1 E t ∨ B] ≤ Σ j∈M Pr[E j ] + Pr[B] ≤ 1 n + 3 4 < 5 6We have shown that with good probability it is possible to create a solution for which all the necessary conditions hold.Dobzinski et al.: Approximations Algorithms for CA\\'s with CF Bidders Mathematics of Operations Research 00(0), pp.\\nxxx-xxx, c 20xx INFORMS 3.2 XOS Valuations.\\nThe algorithm presented in this section is based on exploiting the structure of the syntactically defined XOS class.\\nRecall that the class of XOS valuations strictly contains submodular valuations.The algorithm starts by obtaining a pre-allocation as described in the beginning of the section, where each bidder gets at most one bundle.\\nThe next step is to \"replace\" the valuation of a bidder with the XOS clause that corresponds to the bundle he got in the pre-allocation.\\nNow we find the optimal solution using the \"new\" valuations.\\nObserve that a simple greedy algorithm finds the optimal allocation if all bidders have additive valuations.We are left with showing that the value of the generated allocation is not too far from the optimal fractional solution.\\nOnce again, the syntactic properties of XOS come to our aid: we analyze the algorithm by separately setting a lower bound on the contribution of each single item to the total social welfare.\\n(i) Obtain a \"pre-allocation\" S 1 , ..., S n using the randomized rounding procedure.\\n(ii) Let (x 1 : p i 1 ∨ ... ∨ x m : p i m ) be the maximizing clause for S i in v i .\\n(iii) Allocate the j\\'th item to bidder i for which p i j ≥ p i j , for all i ∈ N .\\nNote that Step (i) requires access to a demand oracle, and Step (ii) requires access to an XOS oracle.\\nWe do not know if an XOS oracle can be simulated using demand queries only, in the case of general XOS valuations.\\nHowever, if a valuation is submodular, a demand oracle (and in fact, a value oracle) suffices, as was shown before.\\nThus, if all valuations are submodular only demand oracles are needed to implement the algorithm.\\n1 1−(1− 1 n ) n )-approximation to the optimal one.Proof.\\nObserve that the allocation produced by the algorithm is indeed a feasible one.\\nThus, all that is left to prove is that it achieves the desired approximation ratio.For every bidder i and bundle S, let (x 1 : p(i,S) 1 ∨ ... ∨ x m : p (i,S)m ) be the maximizing clause for S in v i .\\nIt holds that:OP T * = Σ i,S x i,S v i (S) = Σ i,S x i,S (Σ j p (i,S) j ) = Σ j (Σ i,S x i,S p (i,S) j )Let Q j be the random variable that equals max i∈N {p i j }, after the randomized rounding step.\\nLet ALG be the random variable that receives the value of the total social welfare after assigning each item as in the algorithm.\\nDue to the properties of XOS valuations, ALG ≥ Σ j Q j .\\nThis is because if (x 1 : p(i,S) 1 ∨ ... ∨ x m : p (i,S)m ) is the maximizing clause of S in v i then, by XOS, for everyT ⊆ S Σ j∈T p (i,S) j ≤ v i (T ).\\nWe will now show that the expectation of Q j is bounded from below by (1− (1 − 1 n ) n ) · (Σ i,S x i,S p (i,S) j).\\nThus, by the linearity of expectation:E[ALG] ≥ Σ j E[Q j ] ≥ Σ j (1 − (1 − 1 n ) n ) · (Σ i,S x i,S p (i,S) j ) = (1 − (1 − 1 n ) n )OP T * Lemma 3.3 For every item j, E[Q j ] ≥ (1 − (1 − 1 n ) n ) · (Σ i,S x i,S p (i,S) j )Proof.\\nFix an item j.\\nWe will lower bound the expected value of E[Q j ] by considering a different way of assigning j. LetX j i = Σ S|j∈S x i,S and V j i = Σ S|j∈S x i,S p (i,S) j X j i.\\nThat is, X i is the probability that bidder i gets item j in the \"pre-allocation\", and V j i is the expected value of j to bidder i, conditioned on i receiving j in the \"pre-allocation\".\\nOrder the bidders in the decreasing order of their V j i \\'s.\\nWithout loss of generality, let us assume this order to be 1, ..., n.\\nWe assign j to the highest ranked (first) bidder who got item j in the \"pre-allocation\".\\nDenote by T j the expected value of j in this allocation.Observe that E[Q j ] ≥ E[T j ] because E[Q j ]is the expected value of item j when j is always assigned to the bidder with the highest (per-item) value for j in the \"pre allocation\" (as in the algorithm).\\nTherefore, to prove the lemma we will bound E[T j ] from below.\\nIt is easy to see thatE[T j ] = X j 1 V j 1 + (1 − X j 1 )X j 2 V j 2 + ... + (1 − X j 1 )(1 − X j 2 ) · ... · (1 − X j n−1 )X j n V j nNote that, due to the first condition of the LP, X j 1 + ... + X j n ≤ 1.\\nTherefore, we have for every 1 ≤ k ≤ n that:1 − (1 − X j 1 ) · ... · (1 − X j k ) ≥ 1 − (1 − Σ k i=1 X j i k ) k ≥ (1 − (1 − 1 k ) k )Σ k i=1 X j i ≥ (1 − (1 − 1 n ) n )Σ k i=1 X j i (1)where the last two inequalities are derived using elementary calculus.\\nDefine V j n+1 = 0.\\nMultiplying Equation 1 by (V j k − V j k+1 ) for every 1 ≤ k ≤ n, and summing over all k\\'s shows that:E[T j ] ≥ (1 − (1 − 1 n ) n )(Σ i V j i X j i ) = (1 − (1 − 1 n ) n )(Σ i,S|j∈S x i,S p (i,S) j )3.3 A Combinatorial 2-Approximation Algorithm for XOS Valuations.\\nWe now present a 2-approximation algorithm for combinatorial auctions with XOS bidders.\\nWhile the approximation guarantee is worse than the e e−1 guarantee of the previous algorithm, the current algorithm is combinatorial, fast, and simple.\\nNotice that in Step (ii)a we require access to a demand oracle, and in Step (ii)c we require access to an XOS oracle.\\nProof.\\nFor each T ⊆ M , we denote by p i (T ) the sum of the prices of the items in T at the i\\'th stage of the algorithm.\\nLet ∆ i = p i (M ) − p i−1 (M ), i.e., the total difference in prices between stages (i − 1) and i (with p 0 (M ) = 0).\\nLet A 1 , ..., A n be the allocation generated by the algorithm.\\nLet O 1 , ..., O n be the optimal allocation.\\nWe will prove theΣ i v i (O i ) ≤ 2Σ i v i (A i ).\\nTo do so, we prove three simple lemmas:Lemma 3.4The social welfare of the allocation generated by the algorithm is at least the sum of items\\' prices at the end of the algorithm (after the n\\'th stage).\\nThat is, p n (M ) ≤ Σ i v i (A i ).\\nProof.\\nConsider a specific bidder i. Let T be the bundle assigned to that bidder by the algorithm in stage i. Obviously A i ⊆ T .\\nBecause v i is an XOS valuation, we have that p i (A i ) ≤ v i (A i ).\\nHowever, since the items in A i were not reassigned after the i\\'th stage, and so their prices were not altered,p i (A i ) = p n (A i ).\\nWe have that p n (A i ) ≤ v i (A i ), and so p n (M ) = Σ n i=1 p n (A i ) ≤ Σ n i=1 v i (A i ).\\nLemma 3.5 The prices assigned to the items throughout the execution of the algorithm are non-decreasing.\\nProof.\\nBy contradiction.\\nLet S be the set that maximizes the demand of the i\\'th bidder at the i\\'th stage of the algorithm.\\nLet (x 1 : q 1 ∨ ... ∨ x m : q m ) be the XOS clause of S in v i .\\nNow, assume there is an item j ∈ S for which q j < p i j .\\nv i is an XOS valuation and so we have that Σ t∈(S−{j}) q t ≤ v i (S − {j}) and Σ r∈S q r = v i (S).\\nHence:v i (S) − Σ r∈S p i r = Σ r∈S q r − Σ r∈S p i r = (q j − p i j ) + (Σ t∈(S−{j}) q t − Σ t∈(S−{j}) p i t ) < (Σ t∈(S−{j}) q t − Σ t∈(S−{j}) p i t ) < v i (S − {j}) − Σ t∈(S−{j}) p i tand this is a contradiction to the definition of S.Lemma 3.6 The social welfare of the optimal allocation is at most twice the sum of items\\' prices at the end of the algorithm.\\nThat is,Σ i v i (O i ) ≤ 2p n (M ).\\nProof.\\nRecall that ∆ i represents the \"demand\" of player i at prices p i−1 .\\nHence, for each i, 1 ≤ i ≤ n, ∆ i = max T ⊆M (v i (T ) − p i−1 (T )) (otherwise, i would have chosen a different bundle of items).\\nWe have:v i (O i ) − p i−1 (O i ) ≤ ∆ i .\\nsince the prices do not decrease throughout the algorithm, the following inequality holds:v i (O i ) − p n (O i ) ≤ ∆ i .\\nby summing up on both sides of the equation we get:Σ n i=1 v i (O i ) − Σ i p n (O i ) ≤ Σ i ∆ i Σ i v i (O i ) − p n (M ) ≤ p n (M ) Σ i v i (O i ) ≤ 2p n (M )Putting the lemmas together we have thatΣ i v i (O i ) ≤ 2p n (M ) ≤ 2Σ i v i (A i )The following example shows that the algorithm cannot achieve an approximation ratio better than 2: consider a combinatorial auction with two goods, a and b, and two bidders.\\nThe first bidder\\'s valuation is v 1 ({a}) = v 1 ({b}) = v 1 ({a ∪ b}) = 1.\\nThe valuation of the second bidder is v 2 ({a}) = 0, v 2 ({b}) = v 2 ({a ∪ b}) = 1.\\nA welfare of 2 can be achieved by allocating a to the first bidder, and b to the second bidder.\\nHowever, the first bidder might wish to get b at the first stage, and the optimal social welfare achieved is only 1.\\nHence, the approximation ratio achieved by the algorithm is not better than 2.\\nProof.\\nNisan [15] considers the following combinatorial auction: each bidder i has a set T i of bundles that he is potentially interested in.\\nWe also have that all the T i \\'s have the same size, t.\\nA specific instance of this combinatorial auction is determined by specifying a set I i for each bidder i, I i ⊆ T i , which denotes the bundles our bidder is interested in.\\nThe valuation of each bidder i is the following: v i (S) = 1 if there exists some R ∈ I i such that R ⊆ S, and 0 otherwise.\\nNisan shows that distinguishing between the case where there is (1) an allocation that assigns each bidder i a (superset of a) set he is interested in from I i (and so the optimal welfare is n), and between (2) only one bidder is assigned a superset of a bundle from I i he is interested in (and so the optimal welfare is 1), requires t bits of communication, for t that is exponential in n and m (for n < m 1 2 − ), for any constant > 0.\\nThis shows in particular that every approximation algorithm that provides an approximation ratio better than n for combinatorial auctions with general valuations requires exponential communication.Let us now reduce this combinatorial auction to make the valuations complement free.\\nDefine new complement-free valuations as follows: v i (S) = v i (S) + 1, for S = ∅.\\nThese new valuations are indeedDobzinski et al.: Approximations Algorithms for CA\\'s with CF Bidders Mathematics of Operations Research 00(0), pp.\\nxxx-xxx, c 20xx INFORMS 11 complement free, since the value of each non-empty bundle is at least 1, and no bundle has a value larger than 2.\\nConsider an instance with valuations v 1 , . . . , v n .\\nWe can see that distinguishing between the following cases requires exponential communication: the optimal social welfare is n + 1, and the optimal social welfare is 2n (since distinguishing between these cases is equivalent to distinguishing between the corresponding cases in the auction presented in [15]).\\nHence, we have proved that for every n ≥ 2 achieving Proof.\\nWe will show a polynomial-time reduction from MAX-k-COVER.\\nMAX-k-Cover is defined as follows: Given m items, and a collection of subsets of these items, the objective is to maximize the number of items which can be covered by k subsets.\\nFeige [8] proved that it is NP-hard to approximate this problem within a better factor than e e−1 .\\nThis problem can be converted into a combinatorial auction with XOS valuations: given an instance of MAX-k-COVER, we create an auction with k bidders and m goods.\\nAll bidders will have the same XOS valuation: a clause for each subset in the MAX-k-COVER problem where the value of every item in the clause is 1.\\nObserve that every choice of k subsets in the MAX-k-COVER corresponds to an allocation in the combinatorial auction with the same value, by assigning all items in set i to bidder i (and avoid assigning one item to more then one bidder).\\nIn the other direction, every allocation corresponds to a choice of k sets in MAX-k-COVER with at least the social welfare value: choose k subsets, so that subset i contains the items in the clause maximizing bidder i\\'s gain.\\nHence, we are guaranteed that the number of items covered is no less than the social welfare.\\nThe theorem follows.Next we prove an unconditional communication lower bound.\\nThe proof is based on reduction from the approximate-disjointness problem using a probabilistic construction.\\nThe reduction relies on a combinatorial structure that guarantees the required gap between the optimal solution and all other solutions.\\nWe first define this structure, and then prove its existence via the probabilistic method.\\nProof.\\nWe will prove our lower bound by reducing from the approximate disjointness problem.\\nIn this problem, there are n players, each player i holds a string A i which specifies a subset of {1, ..., t}.\\nThe goal is to distinguish between the following two extreme cases: • ∩ n i=1 A i = ∅ • for every i = j, A i ∩ A j = ∅Alon et al. [1] prove that the communication complexity of this problem is Ω( t n 4 ).\\nThis result also holds for randomized protocols with bounded 2-sided error.We show a reduction from the approximate-disjointness problem on vectors of size t = e 2m n to the problem of finding an optimal solution in combinatorial auctions with XOS bidders.\\nWe then prove a communication lower bound for distinguishing between the case the optimal value is m and the case it is m[1 − (1 − 1 n ) n ].\\nDefinition 4.1 A set of partitions F = {P s } s=1,...,t is said to have the (n, )-covering property if for every choice of indices 1 ≤ s 1 , s 2 , ...s n ≤ t, such that no two are equal, it holds that| ∪ n i=1 P i s i | ≤ m[1 − (1 − 1 n ) n + ].\\nLemma 4.1 For every > 0, there exists a set F of partitions with the (n, )-covering property of size|F | = t = e (1−(1− 1 n ) n )mm 2 3n .\\nProof.\\nWe use probabilistic construction to obtain such a set: each partition P s will be chosen independently at random (each element will be placed in exactly one of the P i s with equal probability).\\nWe will require the following version of the Chernoff bounds:Lemma 4.2 Let X 1 , ..., X m be independent random variables that take values in {0, 1}, such that for all i, Pr[X i = 1] = p for some p. Then, the following holds, for 0 ≤ ≤ 1:Pr[Σ i X i > (1 + )pm] ≤ e − pmm 2 3Fix indices: 1 ≤ s 1 , s 2 , ..., s n ≤ t, such that no two are equal.\\nFor every j ∈ M let Y j be the random variable that receives a value of 1 if j ∈ ∪ n i=1 P i si and 0 otherwise.Observe that E[Y j ] = 1 − (1 − 1 n ) n .\\nUsing the last claim, we have that for any 0 < < 1:Pr[| ∪ n i=1 P i si | > (1 + )m[1 − (1 − 1 n ) n ]] = Pr[Σ j Y j > (1 + )m[1 − (1 − 1 n ) n ]] ≤ e − (1−(1− 1 n ) n )mm 2 3Since there are at most t n choices of such indices we have that as long as t n < e(1−(1− 1 n ) n )mm 2 3such a set of partitions exists.We are now left with describing the reduction.\\nAssume an instance of the approximate-disjointness problem on vectors of size t = e(1−(1− 1 n ) n )mm 2 3n, in which player i receives the string A i ⊆ {1, ..., t}.\\nWe reduce it into a combinatorial auction with n bidders, each with XOS valuation, in the following manner:Let M = {1, ..., m}.\\nPlayer i will construct the collection B i = {P i s |s ∈ A i }.\\nBidder i\\'s valuation will consist of |B i | clauses: ⊗ T ∈B i (∨ t∈T t = 1).\\nIn words, each clause corresponds to a set the player is interested in, and this clause gives a value of 1 to an item if it belongs to the wanted set, and 0 otherwise.Observe that if there exists s ∈ ∩A i , then there is an allocation in which all items are allocated, and the value of the bundle each player gets is simply the number of items he gets.\\nThus, the value of this allocation is m. On the other hand, if for every i = j, A i ∩A j = ∅ then the value of the optimal solution is at most(1 + )m[1 − (1 − 1 n ) n ].\\nThe second observation is since the sets have the (n, )-covering property, so the players get together a value of at most ((1 + )m[1 − (1 − 1 n ) n ])m from the allocated items.\\nSince the communication complexity of the approximate-disjointness problem is Ω( t n 4 ), in our case it is Ω(e(1−(1− 1 n ) n )mm 2 ln n 3n).\\nIn particular, as long as m 1− > n, and for any constant 0 < < 1, the communication complexity is exponential.\\nThis concludes the proof of the theorem.5.\\nTruthful Approximations using Value Queries.5.1 VCG and Maximal in Range Algorithms.\\nArguably the main positive result of mechanism design is the VCG payment scheme.\\nLet us describe this payment scheme when applied to combinatorial auctions.\\nFirst, find the optimal solution (O 1 , ..., O n ), and allocate accordingly.\\nThen, pay each bidder the sum of the utilities of the rest of the bidders.\\nThat is, bidder i receives a payment of Σ k =i v k (O k ).\\nLet us examine the total utility of bidder i: v i (O i ) + Σ k =i v k (O k ) (the value he gains from the bundle he got plus his payment).\\nHence, the total utility of each bidder is equal to the value of the allocation.\\nObserve that the allocation that maximizes the utility of the bidders is the optimal one.\\nBidding untruthfully can only result in changing the allocation to a suboptimal one, hence decreasing the utility of the bidder.\\nThus bidding truthfully is the best action for each bidder 2 .\\nSee [17] for a more formal discussion.The obvious drawback of using the VCG mechanism is that it requires us to find the optimal solution.\\nIn many settings finding the optimal solution is not computationally feasible, and this is true in particular in the settings considered in this paper.\\nIn general, obtaining an approximate solution using an approximation algorithm and using the VCG payment scheme (paying each bidder the sum of the utilities of the rest of the bidders) does not result in a truthful mechanism.\\nIn fact, Nisan and Ronen [18] show that an approximation algorithm becomes truthful using the VCG payment scheme if and only if the underlying algorithm, is essentially maximal in range.An algorithm is maximal in range if it limits the range of possible allocations to a smaller set, and finds the optimal allocation within this restricted range.\\nIncentive compatibility immediately follows using the same argumentation as before since we find the optimal allocation in the restricted range.\\nThe main challenge in the design of these algorithms is therefore to identify a subset of the range in which complete optimization is computationally feasible, and then showing that the optimal solution within the restricted set of solutions always provides the required approximation ratio.\\nWe present a maximal in range algorithm for combinatorial auctions with complement-free bidders.\\nThis algorithm makes use of value queries only.\\nThe approximation ratio of this algorithm is O( √ m).\\nIn contrast, Dobzinski and Schapira [7] and Blumrosen and Nisan [2] showed that for general valuations there is a lower bound of O( m log m ) for the value oracles model.\\nProof.\\nObserve that the algorithm\\'s running time is polynomial in n and m, since maximal weighted matching in bipartite graphs can be solved in polynomial time (in m and n).\\nThe algorithm is clearly a maximal-in-range algorithm, and thus incentive compatibility is guaranteed by the use of the VCG payment scheme.\\nLet us now prove that the algorithm provides the desired approximation ratio.\\nLet OP T = {T 1 , ..., T k , Q 1 , ..., Q l } be the optimal allocation in the original auction, where for each 1 ≤ i ≤ k, |T i | < √ m, and for each 1≤ i ≤ l, |Q i | ≥ √ m. Let |OP T | = Σ l i=1 v i (Q i ) + Σ k i=1 v i (T i ).\\nThe first case we consider is when Σ l i=1 v i (Q i ) ≥ Σ k i=1 v i (T i ).\\nClearly, Σ l i=1 v i (Q i ) ≥ |OP T | 2 .\\nSince l ≤ √ m (otherwise, more than m items were allocated), for the bidder i that maximizes v i (O i ) it holdsthat v i (M ) ≥ v i (Q i ) ≥ |OP T | 2 √ m. Thus, by assigning all items to bidder i we get the desired approximation ratio.Consider the case in whichΣ k i=1 v i (T i ) > Σ l i=1 v i (Q i ).\\nClearly, Σ k i=1 v i (T i ) > |OP T | 2.\\nFor each i, 1 ≤ i ≤ k, let c i = arg max j∈T i v i ({j}).\\nNotice, that v i ({c i }) ≥ vi(Ti)|T i | (this is due to the CF property:|T i | · v i ({c i }) ≥ Σ j∈T i v i ({j}) ≥ v i (T i )).\\nSince for all i\\'s |T i | < √ m, we have that: Σ k i=1 v i (c i ) > Σ i v i (T i ) √ m ≥ |OP T | 2 √ m. By assigning c i to bidder i we get an allocation in which every bidder gets at most one item with a social welfare ofΣ k i=1 v i ({c i }) ≥ |OP T | 2 √ m.\\nThe second allocation, therefore, guarantees at least that social welfare.\\nWe conclude that the approximation ratio the algorithm guarantees is at least O( √ m).6.\\nA Lower Bound for the Value Oracles Model.\\nThe proof of the lower bound takes a concrete complexity approach.\\nThat is, the input is given as a black box that can only answer a specific type of queries.\\nWe only measure the number of queries an algorithm must make in order to achieve a certain approximation ratio.\\nIn particular we ignore any computational work that needs to be done.\\nWe stress that the lower bound we achieve does not depend on any unproven computational assumption.\\nProof.\\nFix a small constant δ > 0.\\nWe shall construct a combinatorial auction with m items and k = √ m bidders.\\nFor every S, let a S be the additive valuation that assigns a value of 1 to each item j ∈ S, and 0 to each item j / ∈ S. Let ¯ a be the additive valuation that assigns every item j ∈ M a value of 1+δ Again, using the fact that T i is chosen uniformly at random we claim that that Pr[|S ∩ T i | > (1 + δ) |S|m 1 2 −δ ] is exponentially small.We conclude that for every bundle S, only with exponentially small probability does one gather sufficient information to distinguish between the case that i\\'s valuation is v i and the case that it is v i .\\nHence, with constant probability it requires an exponential number of value queries to distinguish between v i and v i .\\nThis concludes the proof of the theorem.'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_Frame_val_inputs['Text'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prZtfa8Q_iSX",
        "outputId": "29f64884-66e6-43fd-ddf9-ec3b70e07263"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 2475531.70B/s]\n",
            "100%|██████████| 407873900/407873900 [00:16<00:00, 24582690.34B/s]\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "Extracted_sent=[]\n",
        "\n",
        "Extracted_sent.append(bertSummarize(Data_Frame_val_inputs['Text'][0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "m48SBGLqfWoT",
        "outputId": "9634440e-e0d1-4cf7-d016-3409170fbe16"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[?]\\n. The best deterministic mechanism for complement-free valuations is still the O( √ m)-mechanism presented in this paper.Dobzinski and Nisan [5] proved that one cannot achieve a much better approximation factor using this type of algorithms -maximal in range algorithms (see the discussion in Section 5).1.5 Open Questions. Therefore, if all valuations are submodular, the algorithm presented in this section requires demand queries only (recall that a value query can be simulated by a polynomial number of demand queries [2]). However, when one attempts randomized rounding on packing problems such as combinatorial auctions the results are not good; A randomized choice will very likely yield non-feasible solutions, unless the probabilities chosen reduce the expected quality of solution by a large O( √ m) factor.Both algorithms we present in this section start with a randomized rounding procedure for obtaining a \"pre-allocation\". Theorem 3.1 If all input valuations are complement-free then the algorithm produces an allocation that is an O(k) = O( log m log log m )-approximation to the optimal one.We now prove the theorem. From the first inequality of the LP and using standard probability bounds one can show that for every item j, the probability that it appears in more than k chosen sets is exponentially small in k.\\nThe expected value of i v i (S i ) at this stage is only slightly less than Σ i,S x i,S v i (S) = OP T * . We will prove that Pr[∨ j E j ∨ B] < 5 6 . Fix an item j. Thus, all that is left to prove is that it achieves the desired approximation ratio.For every bidder i and bundle S, let (x 1 : p(i,S) 1 ∨ ... ∨ x m : p (i,S)m ) be the maximizing clause for S in v i . Multiplying Equation 1 by (V j k − V j k+1 ) for every 1 ≤ k ≤ n, and summing over all k\\'s shows that:E[T j ] ≥ (1 − (1 − 1 n ) n )(Σ i V j i X j i ) = (1 − (1 − 1 n ) n )(Σ i,S|j∈S x i,S p (i,S) j )3.3 A Combinatorial 2-Approximation Algorithm for XOS Valuations. Proof. This shows in particular that every approximation algorithm that provides an approximation ratio better than n for combinatorial auctions with general valuations requires exponential communication.Let us now reduce this combinatorial auction to make the valuations complement free. In the other direction, every allocation corresponds to a choice of k sets in MAX-k-COVER with at least the social welfare value: choose k subsets, so that subset i contains the items in the clause maximizing bidder i\\'s gain. We reduce it into a combinatorial auction with n bidders, each with XOS valuation, in the following manner:Let M = {1, ..., m}. This concludes the proof of the theorem.5. Clearly, Σ l i=1 v i (Q i ) ≥ |OP T | 2 . We conclude that the approximation ratio the algorithm guarantees is at least O( √ m).6.'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "''.join(str(v) for v in Extracted_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0XJ5c-GLhbuS",
        "outputId": "03c98911-d6de-415e-dd06-b8f786b52d0b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Finally, we present two approximation algorithms for the more restricted class of XOS valuations: A simple deterministic algorithm that provides an approximation ratio of 2 and an optimal e e−1 approximation achieved via randomized rounding.\\nWe also present optimal lower bounds for both the demand oracles model and the value oracles model.\\nThis approximation ratio may seem quite bad when contrasted with the fact that for the class of submodular valuations constant-approximation algorithms that use only value queries exist (e.g., by Lehmann et al. [12]).\\nHowever, it turns out that this algorithm is optimal in the value oracle model, even if all bidders have XOS valuations, and even ignoring truthfulness constraints: Theorem 1.6 Every approximation algorithm for combinatorial auctions with XOS bidders that uses only value queries, requires an exponential number of queries to achieve an approximation ratio better than m 1 2 − , for any constant > 0.1.4 Subsequent Work.\\nKhot, Lipton, Markakis, and Mehta [11] showed that no approximation better than e e−1 using value queries only is possible, unless P = N P .\\nIn the demand queries model Feige and Vondrak [10] obtained an approximation ratio slightly better than e e−1 .\\nThe best deterministic mechanism for complement-free valuations is still the O( √ m)-mechanism presented in this paper.Dobzinski and Nisan [5] proved that one cannot achieve a much better approximation factor using this type of algorithms -maximal in range algorithms (see the discussion in Section 5).1.5 Open Questions.\\n• It would also be interesting to achieve these approximation ratios using combinatorial algorithms (most state-of-the-art algorithms are based on randomized rounding of the LP relaxation of the problem).\\nWe describe an additive valuations by the following clause:(x 1 : a 1 ∨ x 2 : a 2 ∨ ... ∨ x m : a m )We can now define XOS valuations: Definition 2.1 A valuation v is said to be XOS if there is a set of additive valuations {w 1 , ..., w t }, such that v(S) = max k {w k (S)} for all S ⊆ M .\\nProposition 2.1 Given an XOS valuation as an XOS expression, we can evaluate both XOS queries and demand queries in time polynomial in the input size.Proof.\\nThe entire process requires time polynomial in the input size.If the input is not given as an XOS expression, then we do not know how to answer XOS queries given only a demand oracle.\\nHowever, for the more restricted class of submodular valuations, even the weaker value oracle suffices to answer XOS queries, as the following proposition shows: Proposition 2.2 An XOS clause for a bundle S of a submodular valuation v can be calculated in polynomial time using value queries only.Proof.\\nHowever, when one attempts randomized rounding on packing problems such as combinatorial auctions the results are not good; A randomized choice will very likely yield non-feasible solutions, unless the probabilities chosen reduce the expected quality of solution by a large O( √ m) factor.Both algorithms we present in this section start with a randomized rounding procedure for obtaining a \"pre-allocation\".\\nFeasibility issues are handled differently in the complement free and the XOS cases, and indeed a much better ratio is obtained for the XOS case.Before describing the randomized rounding procedure, let us recall the standard LP relaxation for combinatorial auctions:Maximize: Σ i,S x i,S v i (S) Subject to: -For each item j: Σ i,S|j∈S x i,S ≤ 1 -for each bidder i: Σ S x i,S ≤ 1 -for each i, S: x i,S ≥ 0Even though the linear program has exponentially many variables, it may still be solved in polynomial time.\\nBoth algorithms for XOS valuations we present require in addition access to an XOS oracle.3.1 Complement-Free Valuations.\\nHowever, these non-feasible solutions are only a logarithmic factor away from feasibility (in the sense that with high probability each item is allocated at most a logarithmic number of times).\\n(i) Use randomized rounding to find a \"pre-allocation\" S 1 , ..., S n of pairs < i, S i > with the following properties, where k = O( log m log log m ):• Each item j appears at most k times in {S i } i , with j ∈ S i .\\n(iii) Find the r that maximizes i v i (S r i ), and for each i allocate T i = S r i to bidder i. (iv) If there is a bidder i with v i (M ) ≥ Σ i v i (T i ) then allocate i all items (and allocate nothing to the rest of the bidders).\\nTheorem 3.1 If all input valuations are complement-free then the algorithm produces an allocation that is an O(k) = O( log m log log m )-approximation to the optimal one.We now prove the theorem.\\nIt follows that with very high probability none of the required constraints are violated, and thus we havei v i (S) ≥ 1 3 · OP T * Dobzinskiet al.: Approximations Algorithms for CA\\'s with CF Bidders Mathematics of Operations Research 00(0), pp.\\nThus, the allocation T 1 = S r 1 , ..., T n = S r n is an O( log(m) log log m ) approximation to the optimal allocation (and even to the optimal fractional allocation).\\nFor each j ∈ M , let E j denote the random variable that indicates whether j was allocated more than k times.\\nWe now use the following known proposition, (see, e.g., the book by Mitzenmacher and Upfal [14]):Lemma 3.1 Let X 1 ,...,X n (for sufficiently large n) be independent Bernoulli trials such that for 1 ≤ i ≤ m, Pr[X i = 1] = p i , and Σ i p i = 1.\\nThen Pr[X > 3 log m log log m ] ≤ 1 m 2and thus we have that Pr[item j appears in more than log m 3 log log m bundles in{S i }] ≤ 1 m 2By applying the union bound we get that the probability that any one of the items appears in more than log m 3 log log m bundles in {S i } is smaller than m · 1 m 2 = 1 m .\\nWe will see that A ≥ Σ i v i (S) 3 with high probability.We make use of the following corollary from Chebyshev\\'s inequality:Lemma 3.2 Let X be the sum of independent random variables, each of which lies in [0,1], and letµ = E[X].\\nTherefore, using the union bound:Pr[∨ m t=1 E t ∨ B] ≤ Σ j∈M Pr[E j ] + Pr[B] ≤ 1 n + 3 4 < 5 6We have shown that with good probability it is possible to create a solution for which all the necessary conditions hold.Dobzinski et al.: Approximations Algorithms for CA\\'s with CF Bidders Mathematics of Operations Research 00(0), pp.\\nObserve that a simple greedy algorithm finds the optimal allocation if all bidders have additive valuations.We are left with showing that the value of the generated allocation is not too far from the optimal fractional solution.\\nOnce again, the syntactic properties of XOS come to our aid: we analyze the algorithm by separately setting a lower bound on the contribution of each single item to the total social welfare.\\nThus, all that is left to prove is that it achieves the desired approximation ratio.For every bidder i and bundle S, let (x 1 : p(i,S) 1 ∨ ... ∨ x m : p (i,S)m ) be the maximizing clause for S in v i .\\nThus, by the linearity of expectation:E[ALG] ≥ Σ j E[Q j ] ≥ Σ j (1 − (1 − 1 n ) n ) · (Σ i,S x i,S p (i,S) j ) = (1 − (1 − 1 n ) n )OP T * Lemma 3.3 For every item j, E[Q j ] ≥ (1 − (1 − 1 n ) n ) · (Σ i,S x i,S p (i,S) j )Proof.\\nDenote by T j the expected value of j in this allocation.Observe that E[Q j ] ≥ E[T j ] because E[Q j ]is the expected value of item j when j is always assigned to the bidder with the highest (per-item) value for j in the \"pre allocation\" (as in the algorithm).\\nTherefore, we have for every 1 ≤ k ≤ n that:1 − (1 − X j 1 ) · ... · (1 − X j k ) ≥ 1 − (1 − Σ k i=1 X j i k ) k ≥ (1 − (1 − 1 k ) k )Σ k i=1 X j i ≥ (1 − (1 − 1 n ) n )Σ k i=1 X j i (1)where the last two inequalities are derived using elementary calculus.\\nMultiplying Equation 1 by (V j k − V j k+1 ) for every 1 ≤ k ≤ n, and summing over all k\\'s shows that:E[T j ] ≥ (1 − (1 − 1 n ) n )(Σ i V j i X j i ) = (1 − (1 − 1 n ) n )(Σ i,S|j∈S x i,S p (i,S) j )3.3 A Combinatorial 2-Approximation Algorithm for XOS Valuations.\\nNotice that in Step (ii)a we require access to a demand oracle, and in Step (ii)c we require access to an XOS oracle.\\nTo do so, we prove three simple lemmas:Lemma 3.4The social welfare of the allocation generated by the algorithm is at least the sum of items\\' prices at the end of the algorithm (after the n\\'th stage).\\nHence:v i (S) − Σ r∈S p i r = Σ r∈S q r − Σ r∈S p i r = (q j − p i j ) + (Σ t∈(S−{j}) q t − Σ t∈(S−{j}) p i t ) < (Σ t∈(S−{j}) q t − Σ t∈(S−{j}) p i t ) < v i (S − {j}) − Σ t∈(S−{j}) p i tand this is a contradiction to the definition of S.Lemma 3.6 The social welfare of the optimal allocation is at most twice the sum of items\\' prices at the end of the algorithm.\\nby summing up on both sides of the equation we get:Σ n i=1 v i (O i ) − Σ i p n (O i ) ≤ Σ i ∆ i Σ i v i (O i ) − p n (M ) ≤ p n (M ) Σ i v i (O i ) ≤ 2p n (M )Putting the lemmas together we have thatΣ i v i (O i ) ≤ 2p n (M ) ≤ 2Σ i v i (A i )The following example shows that the algorithm cannot achieve an approximation ratio better than 2: consider a combinatorial auction with two goods, a and b, and two bidders.\\nNisan shows that distinguishing between the case where there is (1) an allocation that assigns each bidder i a (superset of a) set he is interested in from I i (and so the optimal welfare is n), and between (2) only one bidder is assigned a superset of a bundle from I i he is interested in (and so the optimal welfare is 1), requires t bits of communication, for t that is exponential in n and m (for n < m 1 2 − ), for any constant > 0.\\nIn the other direction, every allocation corresponds to a choice of k sets in MAX-k-COVER with at least the social welfare value: choose k subsets, so that subset i contains the items in the clause maximizing bidder i\\'s gain.\\nThis result also holds for randomized protocols with bounded 2-sided error.We show a reduction from the approximate-disjointness problem on vectors of size t = e 2m n to the problem of finding an optimal solution in combinatorial auctions with XOS bidders.\\nIn words, each clause corresponds to a set the player is interested in, and this clause gives a value of 1 to an item if it belongs to the wanted set, and 0 otherwise.Observe that if there exists s ∈ ∩A i , then there is an allocation in which all items are allocated, and the value of the bundle each player gets is simply the number of items he gets.\\nThe second observation is since the sets have the (n, )-covering property, so the players get together a value of at most ((1 + )m[1 − (1 − 1 n ) n ])m from the allocated items.\\nIn fact, Nisan and Ronen [18] show that an approximation algorithm becomes truthful using the VCG payment scheme if and only if the underlying algorithm, is essentially maximal in range.An algorithm is maximal in range if it limits the range of possible allocations to a smaller set, and finds the optimal allocation within this restricted range.\\nObserve that the algorithm\\'s running time is polynomial in n and m, since maximal weighted matching in bipartite graphs can be solved in polynomial time (in m and n).\\nSince for all i\\'s |T i | < √ m, we have that: Σ k i=1 v i (c i ) > Σ i v i (T i ) √ m ≥ |OP T | 2 √ m. By assigning c i to bidder i we get an allocation in which every bidder gets at most one item with a social welfare ofΣ k i=1 v i ({c i }) ≥ |OP T | 2 √ m.\\nFor every S, let a S be the additive valuation that assigns a value of 1 to each item j ∈ S, and 0 to each item j / ∈ S. Let ¯ a be the additive valuation that assigns every item j ∈ M a value of 1+δ Again, using the fact that T i is chosen uniformly at random we claim that that Pr[|S ∩ T i | > (1 + δ) |S|m 1 2 −δ ] is exponentially small.We conclude that for every bundle S, only with exponentially small probability does one gather sufficient information to distinguish between the case that i\\'s valuation is v i and the case that it is v i .\\nHence, with constant probability it requires an exponential number of value queries to distinguish between v i and v i .'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "''.join(str(v) for v in Data_Frame_val_inputs['Target'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLM7jfu_bTZ9",
        "outputId": "9337e068-4f4d-41cc-c797-62cff7608f23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'rouge-1': {'r': 0.34202898550724636, 'p': 0.8939393939393939, 'f': 0.4947589058502433}, 'rouge-2': {'r': 0.19689119170984457, 'p': 0.7215189873417721, 'f': 0.3093622761430789}, 'rouge-l': {'r': 0.3391304347826087, 'p': 0.8863636363636364, 'f': 0.4905660337328429}}]\n"
          ]
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from rouge import Rouge\n",
        "rouge = Rouge()\n",
        "print(rouge.get_scores(''.join(str(v) for v in Extracted_sent), ''.join(str(v) for v in Data_Frame_val_inputs['Target'][0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xO9NU6N-xUi"
      },
      "outputs": [],
      "source": [
        "Data_Frameout=pd.read_csv(\"/content/Final.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdImc1iG_5oV",
        "outputId": "c8ff32cc-1424-4973-8c68-22b2d1a4e32c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3752\n"
          ]
        }
      ],
      "source": [
        "print(len(Data_Frameout))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Asrgb4Rk_BMN"
      },
      "outputs": [],
      "source": [
        "validation_inputs_cleared = Data_Frameout.drop_duplicates(subset=['ReviewID'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mi36M5S9_-Ek"
      },
      "outputs": [],
      "source": [
        "print(len(validation_inputs_cleared))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdiKPcJQ_l5c"
      },
      "outputs": [],
      "source": [
        "for key,ID in validation_inputs_cleared['ReviewID'].items():\n",
        "  for KEY,id in validation_inputs_cleared['ReviewID'].items():\n",
        "    if ID == id :\n",
        "      if validation_inputs_cleared['REVIEWS'][KEY] not in validation_inputs_cleared['REVIEWS'][key]:\n",
        "        validation_inputs_cleared['REVIEWS'][key] = validation_inputs_cleared['REVIEWS'][key] + validation_inputs_cleared['REVIEWS'][KEY]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FwiXrLHMEB_l"
      },
      "source": [
        "# Abstractive Section"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QhzDrbMYV0e7"
      },
      "source": [
        "start training"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
