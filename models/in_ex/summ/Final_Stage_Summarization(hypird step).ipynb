{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "\n",
        "import kaggle\n",
        "\n",
        "!kaggle kernels output mohamedzidan136/t5v2cnndailymail -p /content/simplet5"
      ],
      "metadata": {
        "id": "VuIfwoUOZwvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "7XUG3-p0ZkD9"
      },
      "outputs": [],
      "source": [
        "!pip install torch\n",
        "!pip install pytorch-pretrained-bert\n",
        "!pip install sentence-transformers\n",
        "!pip install Rouge\n",
        "!pip install dataset\n",
        "!pip install evaluate\n",
        "!pip install transformers\n",
        "#!pip install bert-tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "OTedFWVBZkD-"
      },
      "outputs": [],
      "source": [
        "#!pip install dash==1.20.0 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "8rEqaffKZkD_"
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade simplet5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "vscode": {
          "languageId": "polyglot-notebook"
        },
        "id": "NEjM44IrZkD_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4603aca9-1e03-4086-a684-c61b45342eb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import torch\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "vscode": {
          "languageId": "polyglot-notebook"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwGyttCgZkEA",
        "outputId": "f34a87a5-9714-4c5a-faa7-d1eceb03f098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 416801.85B/s]\n",
            "100%|██████████| 407873900/407873900 [00:34<00:00, 11744754.50B/s]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def bertSent_embeding(sentences):\n",
        "   \n",
        "    ## Add sentence head and tail as BERT requested\n",
        "    marked_sent = [\"[CLS] \" +item + \" [SEP]\" for item in sentences]\n",
        "    \n",
        "    tokenized_sent = [tokenizer.tokenize(item ) for item in marked_sent]\n",
        "    \n",
        "\n",
        "    \n",
        "    ## index to BERT vocabulary\n",
        "    indexed_tokens = [tokenizer.convert_tokens_to_ids(item) for item in tokenized_sent]\n",
        "    tokens_tensor = [torch.tensor([item]) for item in indexed_tokens]\n",
        "\n",
        "    ## add segment id as BERT requested\n",
        "    segments_ids = [[1] * len(item) for ind,item in enumerate(tokenized_sent)]\n",
        "    segments_tensors = [torch.tensor([item]) for item in segments_ids]\n",
        "    ## load BERT base model and set to evaluation mode\n",
        "    ##### bert_model = SentenceTransformer('stsb-bert-large')\n",
        "\n",
        "\n",
        "    #model.eval() is a kind of switch for some specific layers/parts of the model that behave differently during training and inference (evaluating) time. \n",
        "    #For example, Dropouts Layers, BatchNorm Layers etc.\n",
        "    #You need to turn them off during model evaluation, and .eval() will do it for you. In addition, \n",
        "    #the common practice for evaluating/validation is using torch.no_grad() in pair with model.eval() to turn off gradients computation:\n",
        "    bert_model.eval()\n",
        "    \n",
        "    ## Output 12 layers of latent vector\n",
        "    assert len(tokens_tensor) == len(segments_tensors)\n",
        "    encoded_layers_list = []\n",
        "    for i in range(len(tokens_tensor)):\n",
        "        with torch.no_grad():\n",
        "            encoded_layers, _ = bert_model(tokens_tensor[i], segments_tensors[i])\n",
        "        encoded_layers_list.append(encoded_layers)\n",
        "    \n",
        "    ## Use only the last layer vetcor **we can use others**\n",
        "  \n",
        "    token_vecs_list =[layers[11][0] for layers in encoded_layers_list]\n",
        "    ## Pooling word vector to sentence vector, use mean pooling\n",
        "    sentence_embedding_list = [torch.mean(vec, dim=0).numpy() for vec in token_vecs_list]\n",
        "\n",
        "    return sentence_embedding_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "vscode": {
          "languageId": "polyglot-notebook"
        },
        "id": "q0nBTZupZkEB"
      },
      "outputs": [],
      "source": [
        "def kmeans_sumIndex(sentence_embedding_list):\n",
        "  \n",
        "    try:\n",
        "      n_clusters =5\n",
        "      #np.ceil(len(sentence_embedding_list)**0.5)\n",
        "      kmeans = KMeans(n_clusters=int(n_clusters))\n",
        "      kmeans = kmeans.fit(sentence_embedding_list)\n",
        "      #Compute minimum distances between one point and a set of points.\n",
        "      #get centers and compare with sentence_embedding by bert !!!!(\"centers is the most common sentences\")\n",
        "      sum_index,_ = pairwise_distances_argmin_min(kmeans.cluster_centers_, sentence_embedding_list,metric='euclidean')\n",
        "      sum_index = sorted(sum_index)\n",
        "      return sum_index\n",
        "    except:\n",
        "      n_clusters =1\n",
        "      #np.ceil(len(sentence_embedding_list)**0.5)\n",
        "      kmeans = KMeans(n_clusters=int(n_clusters))\n",
        "      kmeans = kmeans.fit(sentence_embedding_list)\n",
        "      #Compute minimum distances between one point and a set of points.\n",
        "      #get centers and compare with sentence_embedding by bert !!!!(\"centers is the most common sentences\")\n",
        "      sum_index,_ = pairwise_distances_argmin_min(kmeans.cluster_centers_, sentence_embedding_list,metric='euclidean')\n",
        "      sum_index = sorted(sum_index)\n",
        "      return sum_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "vscode": {
          "languageId": "polyglot-notebook"
        },
        "id": "JneZfcdWZkEC"
      },
      "outputs": [],
      "source": [
        "def bertSummarize(text):\n",
        "  \n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    sentence_embedding_list = bertSent_embeding(sentences)\n",
        "\n",
        "    sum_index = kmeans_sumIndex(sentence_embedding_list)\n",
        "    \n",
        "    summary = ' '.join([sentences[ind] for ind in sum_index])\n",
        "   \n",
        "    return summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "ymBBzvHDZkEE"
      },
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "T5_PATH = '/content/simplet5/outputs/best_model' \n",
        "t5_tokenizer = T5Tokenizer.from_pretrained(T5_PATH)\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained(T5_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "hFWYJAksZkEG"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Off-Policy reinforcement learning has been a\n",
        "driving force for the state-of-the-art conversational AIs leading to more natural humanagent interactions and improving the user satisfaction for goal-oriented agents. However,\n",
        "in large-scale commercial settings, it is often challenging to balance between policy improvements and experience continuity on the\n",
        "broad spectrum of applications handled by\n",
        "such system. In the literature, off-policy evaluation and guard-railing on aggregate statistics\n",
        "has been commonly used to address this problem. In this paper, we propose a method for curating and leveraging high-precision samples\n",
        "sourced from historical regression incident reports to validate, safe-guard, and improve policies prior to the online deployment. We conducted extensive experiments using data from\n",
        "a real-world conversational system and actual\n",
        "regression incidents. The proposed method is\n",
        "currently deployed in our production system to\n",
        "protect customers against broken experiences\n",
        "and enable long-term policy improvements.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "l8PlLizO5eUq",
        "outputId": "7738dc00-7c2e-40df-8fcb-e7f1674f7039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Off-Policy reinforcement learning has been a\\ndriving force for the state-of-the-art conversational AIs leading to more natural humanagent interactions and improving the user satisfaction for goal-oriented agents. However,\\nin large-scale commercial settings, it is often challenging to balance between policy improvements and experience continuity on the\\nbroad spectrum of applications handled by\\nsuch system. In the literature, off-policy evaluation and guard-railing on aggregate statistics\\nhas been commonly used to address this problem. In this paper, we propose a method for curating and leveraging high-precision samples\\nsourced from historical regression incident reports to validate, safe-guard, and improve policies prior to the online deployment. We conducted extensive experiments using data from\\na real-world conversational system and actual\\nregression incidents. The proposed method is\\ncurrently deployed in our production system to\\nprotect customers against broken experiences\\nand enable long-term policy improvements.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PkL6UTpZkEG",
        "outputId": "9397e771-8a03-4e49-8164-ea4bc2142b88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "ext_summary= bertSummarize(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ext_summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "WfSLcMIwcbKw",
        "outputId": "1c604cdb-52f8-4671-b2ce-cd54fb2eb84a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Off-Policy reinforcement learning has been a\\ndriving force for the state-of-the-art conversational AIs leading to more natural humanagent interactions and improving the user satisfaction for goal-oriented agents. However,\\nin large-scale commercial settings, it is often challenging to balance between policy improvements and experience continuity on the\\nbroad spectrum of applications handled by\\nsuch system. In the literature, off-policy evaluation and guard-railing on aggregate statistics\\nhas been commonly used to address this problem. In this paper, we propose a method for curating and leveraging high-precision samples\\nsourced from historical regression incident reports to validate, safe-guard, and improve policies prior to the online deployment. We conducted extensive experiments using data from\\na real-world conversational system and actual\\nregression incidents.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = t5_tokenizer.encode(\"summarize:\" + ext_summary, return_tensors=\"pt\", max_length=512, padding='max_length', truncation=True)"
      ],
      "metadata": {
        "id": "uSfvhepWDquv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_ids = t5_model.generate(inputs,\n",
        "\n",
        "                                    num_beams=int(2),\n",
        "\n",
        "                                    no_repeat_ngram_size=3,\n",
        "\n",
        "                                    length_penalty=2.0,\n",
        "\n",
        "                                    min_length=100,\n",
        "\n",
        "                                    max_length=200,\n",
        "\n",
        "                                    early_stopping=True)\n",
        "\n",
        "output = t5_tokenizer.decode(summary_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n"
      ],
      "metadata": {
        "id": "hXw4UObA4UZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "Fs4XKITo4xGb",
        "outputId": "718a5ddb-4d83-4403-f788-9dc04f2d8a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Off-Policy reinforcement learning has been a driving force for conversational AIs. In large-scale commercial settings, it is often difficult to balance between policy improvements and experience continuity. We conducted extensive experiments using data from historical regression incident reports. This paper propose a method for curating and leveraging high-precision samples from historical. regression incidents to validate, safe-guard, and improve policies prior to the online deployment. 'It is often challenging to balance policy improvements with experience continuity on the broad spectrum of applications handled by such systems'\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m5IVDTCN0L-u"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "default:Python",
      "language": "python",
      "name": "conda-env-default-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}